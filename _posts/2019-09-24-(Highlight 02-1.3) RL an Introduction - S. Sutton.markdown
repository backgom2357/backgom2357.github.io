---
layout: post
title: 'Highlight02 - 1.3 Elements of Reinforcement Learning <br> [RL an Introduction - S. Sutton]'
date: 2019-09-25
categories: machine_learning
image: images/RLIntroduction_Sutton.png
---
### 1.3 Elements of Reinforcement Learning
Beyond the agent and the environment, one can identify four main subelements of a reinforcement learning system:
- a policy
- a reward signal
- a value function
- (optionally) a model of the environment
<br>

A policy defines the learning agent's way of behaving at a given time. Roughly speaking, a policy is a mapping from perceived states of the environment to actions to be taken when in those states.
<br>

The policy is the core of a reinforcement learning in the sense that it alone is sufficient to determine behavior. In general, policies may be stochastic, specifying probabilities for each action.
<br>

A reward signal defines the goal of a reinforcement learning problem.
<br>

In general, reward signals may be stochastic functions of the state of the environment and the actions taken.
<br>

A value function specifies what is good in the long run.
<br>

Wheras rewards determine the immediate, intrinsic desirability of environmental states, values indicate the long-term desirability of states after taking into account the states that are likely to follow and the rewards available in those states.
<br>

Rewards are in a sense primary, whereas values, as predictions of rewards, are secondary. Without rewards there could be no values, and the only purpose of estimating values is to achieve more reward.
<br>

We seek actions that bring about states of highest values, not highest reward, because these actions obtain the greatest amount of reward for us over the long run.
<br>

The fourth and final element of some reinforcement learning systems is a model of the environment. This is something that mimics the behavior of the environment, or more generally, that allows inferences to be made about how the environment will behave.
<br>

Models are used for planning, by which we mean any way of deciding on a course of action by considering possible futuresituations before they are actually experienced. Methods for solving reinforcement learning problems that use models and planning are called model-based methods, as opposed to simpler model-free methods that are explicitly trial-and-error learners -- viewed as almost the opposite of planning.
<br>

Modern reinforcement learning spans the spectrum from low-level, trial-and-error learning to high-level, deliberative planning.

<br>
\-----------------

# Reinforcement Learning an Introduction - Richard S. Sutton

#### 1 Introduction 1
1.1 Reinforcement Learning<br>
1.2 Examples<br>
<b>1.3 Elements of Reinforcement Learning<br></b>
1.4 Limitations and Scope<br>
1.5 An Extended Example: Tic-Tac-Toe<br>
1.6 Summary<br>
1.7 Early History of Reinforcement Learning<br>
